# Configuraci√≥n adicional para la aplicaci√≥n
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    """Configuraci√≥n de la aplicaci√≥n"""
    
    # Flask settings
    SECRET_KEY = os.environ.get('SECRET_KEY') or 'tu-clave-secreta-super-segura'
    DEBUG = True
    
    # Ollama/Llama3 settings (no requiere API key)
    OLLAMA_MODEL = "llama3"
    OLLAMA_BASE_URL = "http://localhost:11434"
    
    # LangChain settings
    LANGCHAIN_VERBOSE = True
    LANGCHAIN_MAX_ITERATIONS = 3
    
    # Chat settings
    DEFAULT_TEMPERATURE = 0.7
    MAX_TOKENS = 1000
    
    @staticmethod
    def validate_config():
        """Validar que Ollama est√© disponible"""
        import requests
        try:
            response = requests.get(f"{Config.OLLAMA_BASE_URL}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                llama_available = any('llama3' in model.get('name', '') for model in models)
                if llama_available:
                    print("‚úÖ Configuraci√≥n validada correctamente")
                    print(f"ü¶ô Llama3 disponible en Ollama")
                    return True
                else:
                    raise ValueError("Modelo llama3 no encontrado en Ollama")
            else:
                raise ValueError("Ollama no responde correctamente")
        except Exception as e:
            print(f"‚ùå Error verificando Ollama: {e}")
            print("ÔøΩ Aseg√∫rate de que Ollama est√© ejecut√°ndose y tengas llama3 instalado")
            print("üîß Ejecuta: ollama pull llama3")
            return False
